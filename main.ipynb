{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Joshbazz/Neural_Network_Trading_Algo/blob/main/main.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from IPython.display import Image, display\n",
    "# !pip install backtesting\n",
    "from backtesting import Backtest, Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StockPricePrediction:\n",
    "    def __init__(self, data_path, window_size=40):\n",
    "        self.data_path = data_path\n",
    "        self.window_size = window_size\n",
    "        self.model = None\n",
    "        self.scaler = RobustScaler()\n",
    "        self.y_scaler = RobustScaler()\n",
    "    \n",
    "    def load_and_preprocess_data(self):\n",
    "        data = pd.read_csv(self.data_path, parse_dates=True, index_col='Date')\n",
    "        data_create = data['Close'].copy()\n",
    "        return data, data_create\n",
    "\n",
    "    def create_dataset(self, prices):\n",
    "        data = []\n",
    "        for i in range(len(prices) - self.window_size):\n",
    "            X = prices[i:i + self.window_size]\n",
    "            y = prices.iloc[i + self.window_size]\n",
    "            data.append(list(X) + [y])\n",
    "        columns = [f't-{i}' for i in range(self.window_size, 0, -1)] + ['t']\n",
    "        return pd.DataFrame(data, columns=columns)\n",
    "\n",
    "    def normalize_data(self, X_train, y_train):\n",
    "        self.scaler.fit(X_train)\n",
    "        X_train_scaled = self.scaler.transform(X_train)\n",
    "        y_train = y_train.values.reshape(-1, 1)\n",
    "        self.y_scaler.fit(y_train)\n",
    "        y_train_scaled = self.y_scaler.transform(y_train)\n",
    "        return X_train_scaled, y_train_scaled\n",
    "\n",
    "    def inverse_transform(self, y_scaled, predictions_scaled):\n",
    "        y_inv = self.y_scaler.inverse_transform(y_scaled).flatten()\n",
    "        predictions_inv = self.y_scaler.inverse_transform(predictions_scaled).flatten()\n",
    "        return y_inv, predictions_inv\n",
    "\n",
    "    def build_model(self):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(10, input_dim=self.window_size, activation='relu'))\n",
    "        model.add(Dense(10, activation='relu'))\n",
    "        model.add(Dense(10, activation='relu'))\n",
    "        model.add(Dense(1))\n",
    "        model.compile(optimizer=SGD(learning_rate=0.001), loss='mean_squared_error', metrics=[tf.keras.metrics.MeanAbsolutePercentageError()])\n",
    "        self.model = model\n",
    "\n",
    "    def train_model(self, X_train_scaled, y_train_scaled, epochs=50):\n",
    "        self.model.fit(X_train_scaled, y_train_scaled, epochs=epochs, batch_size=32, validation_split=0.2, verbose=1)\n",
    "\n",
    "    def evaluate_model(self, X_test_scaled, y_test_scaled):\n",
    "        loss = self.model.evaluate(X_test_scaled, y_test_scaled, verbose=2)\n",
    "        predictions = self.model.predict(X_test_scaled)\n",
    "        return loss, predictions\n",
    "\n",
    "    def save_model(self, epochs=50):\n",
    "        current_timestamp = datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "        model_path = f'{current_timestamp}_stock_price_prediction_model_epochs_{epochs}.keras'\n",
    "        self.model.save(model_path)\n",
    "        print(\"Model saved successfully.\")\n",
    "        return model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_signal(model_path, data_path, test_size, window_size=40):\n",
    "    # Load the saved model\n",
    "    model = load_model(model_path)\n",
    "\n",
    "    # Load new data for backtesting\n",
    "    new_data = pd.read_csv(data_path, parse_dates=True, index_col='Date')\n",
    "\n",
    "    # Calculate the index for splitting into 75% training and 25% testing\n",
    "    split_index = int(len(new_data) * (1 - test_size))\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    data = new_data.iloc[split_index:]\n",
    "    data = data.dropna()\n",
    "    prices = data['Close'].copy()\n",
    "\n",
    "    print(type(prices))\n",
    "\n",
    "    # Preprocess the new data using the same window size as during training\n",
    "    def create_backtest_data(prices, window_size):\n",
    "        data = []\n",
    "        for i in range(len(prices) - window_size):\n",
    "            X_new = prices.iloc[i:i + window_size]\n",
    "            y = prices.iloc[i + window_size]\n",
    "            data.append(list(X_new) + [y])\n",
    "        columns = [f't-{i}' for i in range(window_size, 0, -1)] + ['t']\n",
    "        return pd.DataFrame(data, columns=columns)\n",
    "\n",
    "    dataset = create_backtest_data(prices, window_size)\n",
    "\n",
    "    # Assign target and feature sets\n",
    "    X = dataset.iloc[:, :-1]\n",
    "    y = dataset.iloc[:, -1].values.reshape(-1, 1)\n",
    "\n",
    "    # Normalize features (using the same scaler as during training)\n",
    "    scaler = RobustScaler()\n",
    "    scaler.fit(X)\n",
    "    X_scaled = scaler.transform(X)\n",
    "\n",
    "    scaler_y = RobustScaler()\n",
    "    scaler_y.fit(y)\n",
    "    y_scaled = scaler_y.transform(y)\n",
    "\n",
    "    # Predict with the model\n",
    "    predictions_scaled = model.predict(X_scaled)\n",
    "\n",
    "    # Inverse transform predictions to get unscaled prices\n",
    "    predictions = scaler_y.inverse_transform(predictions_scaled).flatten()\n",
    "\n",
    "    # Implement trading strategy based on unscaled predictions\n",
    "    positions = []\n",
    "    current_position = 0\n",
    "\n",
    "    for i in range(len(predictions)):\n",
    "        # Buy if predicted close for the next day is higher than current day's open\n",
    "        if predictions[i] > data['Open'].iloc[i + window_size] and current_position <= 0:\n",
    "            positions.append(1)  # 1 indicates BUY\n",
    "            current_position += 1\n",
    "        # Sell if predicted close for the next day is lower than current day's open\n",
    "        elif predictions[i] < data['Open'].iloc[i + window_size]:\n",
    "            if current_position > 0:\n",
    "                positions.append(-1)  # -1 indicates SELL\n",
    "                current_position = 0\n",
    "            else:\n",
    "                positions.append(0)  # 0 indicates no action\n",
    "        else:\n",
    "            positions.append(0)  # No action if none of the conditions are met\n",
    "\n",
    "    # Handle last day: sell remaining position if any\n",
    "    if current_position > 0:\n",
    "        positions.append(-1)\n",
    "\n",
    "    # Adjust data to match the length of positions\n",
    "    data_adjusted = data.iloc[window_size:].copy()\n",
    "\n",
    "    # Ensure positions length matches data_adjusted length\n",
    "    positions = positions[:len(data_adjusted)]\n",
    "\n",
    "    # Add positions to the adjusted DataFrame\n",
    "    data_adjusted['Signal'] = positions\n",
    "\n",
    "    # Get the current timestamp and format it\n",
    "    current_timestamp = datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "\n",
    "    # Save new_data with positions\n",
    "    data_adjusted.to_csv(f'{current_timestamp}_new_data_with_positions.csv', index=True)\n",
    "\n",
    "    print(f\"Data shape: {data_adjusted.shape}\")\n",
    "    print(f\"Positions length: {len(positions)}\")\n",
    "\n",
    "    data_string = f'{current_timestamp}_new_data_with_positions.csv'\n",
    "\n",
    "    return data_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_and_visualize_model(model_path):\n",
    "\n",
    "    model = load_model(model_path)\n",
    "\n",
    "    # Generate a timestamp for the model file\n",
    "    timestamp = datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "\n",
    "    # Define the image path in the current directory\n",
    "    img_path = f\"model_{timestamp}.png\"\n",
    "    print(f\"Saving model visualization to: {img_path}\")\n",
    "\n",
    "    # Plot the model and save it as a PNG image\n",
    "    plot_model(\n",
    "        model,\n",
    "        to_file=img_path,\n",
    "        show_shapes=True,\n",
    "        show_dtype=False,\n",
    "        show_layer_names=True,\n",
    "        rankdir=\"TB\",\n",
    "        expand_nested=False,\n",
    "        dpi=200,\n",
    "        show_layer_activations=True,\n",
    "        show_trainable=True\n",
    "    )\n",
    "\n",
    "    # Display the image\n",
    "    img = Image(filename=img_path)\n",
    "    display(img)\n",
    "    print(f\"Model visualization saved and displayed from {img_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SignalStrategy(Strategy):\n",
    "    def init(self):\n",
    "        self.signal = self.data.Signal\n",
    "\n",
    "    def next(self):\n",
    "        current_signal = self.data.Signal[-1]\n",
    "        current_date = self.data.index[-1]\n",
    "        print(f\"Date: {current_date}, Current position size: {self.position.size}, Signal: {current_signal}, Position: {self.position.is_long}\")\n",
    "        \n",
    "        if current_signal == 1:\n",
    "            print(\"Executing BUY order\")\n",
    "            self.buy(size=1)\n",
    "        elif current_signal == -1 and self.position.is_long:\n",
    "            print(\"Attempting to SELL entire position\")\n",
    "            try:\n",
    "                self.position.close()  # This closes the entire position\n",
    "                print(\"SELL order executed - entire position closed\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error executing SELL order: {e}\")\n",
    "        elif current_signal == 0:\n",
    "            print(\"No trade executed\")\n",
    "\n",
    "def run_backtest(data_path, cash=1_000_000, commission=0.002, trade_on_close=True):\n",
    "    # Load and preprocess the data\n",
    "    dataframe = pd.read_csv(data_path, index_col='Date', parse_dates=True)\n",
    "    dataframe = dataframe.sort_index()\n",
    "    dataframe = dataframe.dropna()\n",
    "    dataframe = dataframe.drop_duplicates()\n",
    "\n",
    "    # Rename the columns to match the required format\n",
    "    dataframe.columns = [column.capitalize() for column in dataframe.columns]\n",
    "\n",
    "    # Initialize and run the backtest\n",
    "    bt = Backtest(dataframe, SignalStrategy, cash=cash, commission=commission, trade_on_close=trade_on_close)\n",
    "    stats = bt.run()\n",
    "\n",
    "    # Print the statistics and plot the backtest results\n",
    "    print(stats)\n",
    "    bt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_and_save_data(ticker, start_date, end_date, file_path):\n",
    "\n",
    "    # Fetch the historical data\n",
    "    data = yf.download(ticker, start=start_date, end=end_date)\n",
    "    \n",
    "    # Save the data to a CSV file\n",
    "    data.to_csv(file_path)\n",
    "    \n",
    "    print(f\"Data for {ticker} from {start_date} to {end_date} has been saved to {file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "# Define the data path\n",
    "ticker = '^STI'  # Example ticker\n",
    "start_date = '2010-01-01'\n",
    "end_date = '2017-01-03'\n",
    "file_path = f'{ticker}_data_end_{end_date}_start_{start_date}.csv'\n",
    "\n",
    "# fetch data from Yahoo Finance and save to CSV\n",
    "fetch_and_save_data(ticker, start_date, end_date, file_path)\n",
    "\n",
    "# Create an instance of the class\n",
    "stock_predictor = StockPricePrediction(file_path)\n",
    "\n",
    "# set the test_size. if test size is .25, then 75% of data will be used to train\n",
    "test_size = 0.25\n",
    "\n",
    "# Load and preprocess data\n",
    "# train_percent [0,1] => determines percent of data that goes to training\n",
    "data, data_create = stock_predictor.load_and_preprocess_data()\n",
    "\n",
    "# Create dataset\n",
    "dataset = stock_predictor.create_dataset(data_create)\n",
    "X = dataset.iloc[:, :-1]\n",
    "y = dataset.iloc[:, -1]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n",
    "\n",
    "# retain X_test slice of original dataframe\n",
    "backtest_data = data.iloc[-len(X_test):].copy()\n",
    "\n",
    "# Normalize data\n",
    "X_train_scaled, y_train_scaled = stock_predictor.normalize_data(X_train, y_train)\n",
    "X_test_scaled, y_test_scaled = stock_predictor.scaler.transform(X_test), stock_predictor.y_scaler.transform(y_test.values.reshape(-1, 1))\n",
    "\n",
    "# set the amount of epochs. default is 50\n",
    "epochs = 50\n",
    "\n",
    "# Build and train model\n",
    "stock_predictor.build_model()\n",
    "stock_predictor.train_model(X_train_scaled, y_train_scaled, epochs=epochs)\n",
    "\n",
    "# # Evaluate model\n",
    "loss, predictions = stock_predictor.evaluate_model(X_test_scaled, y_test_scaled)\n",
    "\n",
    "# Inverse transform predictions and actual values\n",
    "y_test_inv, predictions_inv = stock_predictor.inverse_transform(y_test_scaled, predictions)\n",
    "\n",
    "# Save the model\n",
    "model_path = stock_predictor.save_model(epochs=epochs)\n",
    "\n",
    "# uncomment when bug fixed\n",
    "save_and_visualize_model(model_path)\n",
    "\n",
    "# Generate Signals csv\n",
    "signals_string = generate_signal(model_path, file_path, test_size)\n",
    "\n",
    "# Call the function with the path to your CSV file\n",
    "run_backtest(signals_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neural_network_trading_algo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
